{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Drop source and target tables**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "\r\n",
        "drop table if exists sparkdb.TESTsource;\r\n",
        "drop table if exists sparkdb.TESTtarget"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Declare source and target tables**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "\r\n",
        "create table if not exists sparkdb.TESTtarget (recid INT, name STRING, segment STRING, SCDcurrent STRING, SCDeffectiveDate STRING, SCDendDate STRING) using delta;\r\n",
        "create table if not exists sparkdb.TESTsource (recid INT, name STRING, segment STRING) using delta"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": 115,
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:07:20.4217462Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:11:05.6593796Z",
              "execution_finish_time": "2022-01-17T17:11:05.6595705Z"
            },
            "text/plain": "StatementMeta(, 115, -1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill in data into source-table**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "\r\n",
        "insert into sparkdb.TESTsource values(1,\"FaetterBR\",\"legetøjsbutik\"), (2,\"ToysRUs\",\"legetøjsbutik\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:07:21.6035598Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:11:06.0364868Z",
              "execution_finish_time": "2022-01-17T17:11:13.2945049Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check source-table**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM `sparkdb`.`testsource`\").show(10)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:11:18.2541527Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:11:26.0547377Z",
              "execution_finish_time": "2022-01-17T17:11:31.6680079Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+-------------+\n|recid|     name|      segment|\n+-----+---------+-------------+\n|    1|FaetterBR|legetøjsbutik|\n|    2|  ToysRUs|legetøjsbutik|\n+-----+---------+-------------+"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check target-table**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "spark.sql(\"SELECT * FROM `sparkdb`.`testtarget`\").show(10)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:11:33.2626706Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:11:33.739086Z",
              "execution_finish_time": "2022-01-17T17:11:36.6222276Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+-------+----------+----------------+----------+\n|recid|name|segment|SCDcurrent|SCDeffectiveDate|SCDendDate|\n+-----+----+-------+----------+----------------+----------+\n+-----+----+-------+----------+----------------+----------+"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create SCD-function**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Best way to parameterize target-table in below function is to declare this as an outer variable\r\n",
        "targetTableName = \"sparkdb.testtarget\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:11:39.0778105Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:11:39.473357Z",
              "execution_finish_time": "2022-01-17T17:11:39.9660663Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 8, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\r\n",
        "from pyspark.sql.types import *\r\n",
        "from delta.tables import *\r\n",
        "\r\n",
        "def SCDdeltaOnStream(microdf,batchid):\r\n",
        "\r\n",
        "  # Declare target-table and source-object. Source-object is added SCD control-columns\r\n",
        "  targetTable = DeltaTable.forName(spark, targetTableName)\r\n",
        "  microdf = (microdf\r\n",
        "      .withColumn(\"SCDcurrent\",lit(\"true\"))\r\n",
        "      .withColumn(\"SCDeffectiveDate\",current_timestamp())\r\n",
        "      .withColumn(\"SCDendDate\",lit(\"NULL\"))\r\n",
        "      )\r\n",
        "  \r\n",
        "  # key-column for matching is declared along with the SCD-columns triggering new records when updated.\r\n",
        "  matchColumn = \"recid\"\r\n",
        "  SCDcolumns = ['name','segment']\r\n",
        "\r\n",
        "  # Identify columns not included in the ListOfSCDcolumns but still to be updated by matching records ensuring new and existing data is aligned\r\n",
        "  NoneSCDcolumns = [col for col in DeltaTable.forName(spark,targetTableName).toDF().schema.names if col not in SCDcolumns + list(matchColumn) + ['SCDcurrent','SCDeffectiveDate','SCDendDate']]\r\n",
        " \r\n",
        "  # Rows with new values in SCD-columns for existing records in the target is set aside\r\n",
        "  newLabelsToInsert = (microdf\r\n",
        "    .alias(\"updates\")\r\n",
        "    .join(targetTable.toDF().alias(\"target\"), f\"{matchColumn}\")\r\n",
        "    .where(\"target.SCDcurrent = true AND ({input})\".format(input=\" OR \".join(['updates.'+i+ ' <> ' + 'target.' + i for i in SCDcolumns])))\r\n",
        "  )\r\n",
        "\r\n",
        "  # Stage the update by unioning two sets of rows\r\n",
        "  # 1. The rows that has just been set aside in above step (these are to be inserted as \"current\" versions of existing records)\r\n",
        "  # 2. Rows that will either update the current attribute-labels of existing records or insert the new labels of new records\r\n",
        "  stagedUpdates = (\r\n",
        "    newLabelsToInsert\r\n",
        "    .selectExpr(\"NULL as mergeKey\", \"updates.*\")   # Rows for 1\r\n",
        "    .union(microdf.selectExpr(f\"{matchColumn} as mergeKey\", \"*\"))  # Rows for 2.\r\n",
        "  )\r\n",
        "\r\n",
        "  # Apply SCD Type 2 operation using merge.\r\n",
        "  # None-matching records can be grouped in following two categories: 1) rows reflecting new SCD-values for existing records, and 2) entirely new records.\r\n",
        "  #M atching records can be grouped in two categories: 1) existing records with old SCD-values needing to be marked as obsolete and provided and SCDendDate, and 2) existing records where there might/might not be updates to none-SCD-columns \r\n",
        "  targetTable.alias(\"target\").merge(\r\n",
        "    stagedUpdates.alias(\"staged_updates\"),f\"target.{matchColumn} = mergeKey\"\r\n",
        "  ).whenMatchedUpdate(\r\n",
        "    condition = \"target.SCDcurrent = true AND ({input})\".format(input=\" OR \".join(['target.'+i+ ' <> ' + 'staged_updates.' + i for i in SCDcolumns])),\r\n",
        "    set = {                                      # Set current to false and endDate to source's effective date.\r\n",
        "      \"SCDcurrent\": \"false\",\r\n",
        "      \"SCDendDate\": current_timestamp()\r\n",
        "    }\r\n",
        "  ).whenMatchedUpdate(\r\n",
        "    condition = \"target.SCDcurrent = true AND ({input})\".format(input=\" AND \".join(['target.'+i+ ' = ' + 'staged_updates.' + i for i in SCDcolumns])),\r\n",
        "    set = {'target.'+col : 'staged_updates.'+col for col in NoneSCDcolumns}\r\n",
        "  ).whenNotMatchedInsertAll().execute()\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:11:41.12089Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:11:41.5133514Z",
              "execution_finish_time": "2022-01-17T17:11:41.927023Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 9, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up streamRead and Write between source and target**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = (spark.readStream\r\n",
        "    .format(\"delta\")\r\n",
        "    .table(\"sparkdb.testsource\")\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:11:43.9591524Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:11:44.3198096Z",
              "execution_finish_time": "2022-01-17T17:11:46.2563984Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 10, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamQuery = (df.writeStream\r\n",
        "    .format(\"delta\")\r\n",
        "    ##.outputMode(\"append\")\r\n",
        "    .foreachBatch(SCDdeltaOnStream)\r\n",
        "    .option(\"checkpointLocation\",\"abfss://<your own container@daxdatalakestorage.dfs.core.windows.net/<folderstorage>\")\r\n",
        "    .option(\"mergeSchema\",True)\r\n",
        "    ##.trigger(once=True)\r\n",
        "    .start()\r\n",
        "    )"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:11:46.9975745Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:11:47.3808964Z",
              "execution_finish_time": "2022-01-17T17:11:54.5288929Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 11, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check content of target-cell to see it has been updated with source-data (if no result remember to delete checkpoint-dir)**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "spark.sql(\"SELECT * FROM `sparkdb`.`testtarget`\").show(10)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 26,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:12:29.0203586Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:12:29.3847556Z",
              "execution_finish_time": "2022-01-17T17:12:33.644583Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 26, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+-------------+----------+--------------------+----------+\n|recid|     name|      segment|SCDcurrent|    SCDeffectiveDate|SCDendDate|\n+-----+---------+-------------+----------+--------------------+----------+\n|    1|FaetterBR|legetøjsbutik|      true|2022-01-17 17:12:...|      NULL|\n|    2|  ToysRUs|legetøjsbutik|      true|2022-01-17 17:12:...|      NULL|\n+-----+---------+-------------+----------+--------------------+----------+"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamQuery.status"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 27,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:12:38.6606172Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:12:39.0612906Z",
              "execution_finish_time": "2022-01-17T17:12:39.4784311Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 27, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "{'message': 'Processing new data',\n 'isDataAvailable': True,\n 'isTriggerActive': True}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add new row to source-table**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "insert into sparkdb.TESTsource values(3,\"HammerFedt\",\"grovsmed\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 25,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:12:22.980698Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:12:23.3958237Z",
              "execution_finish_time": "2022-01-17T17:12:29.0018618Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 25, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "spark.sql(\"SELECT * FROM `sparkdb`.`testsource`\").show(10)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 28,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:12:42.0763272Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:12:42.4542311Z",
              "execution_finish_time": "2022-01-17T17:12:46.5644859Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 28, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-------------+\n|recid|      name|      segment|\n+-----+----------+-------------+\n|    1| FaetterBR|legetøjsbutik|\n|    2|   ToysRUs|legetøjsbutik|\n|    3|HammerFedt|     grovsmed|\n+-----+----------+-------------+"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check target-table to see new row**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "spark.sql(\"SELECT * FROM `sparkdb`.`testtarget`\").show(10)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 29,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:12:47.9176936Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:12:48.3048657Z",
              "execution_finish_time": "2022-01-17T17:12:51.1995117Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 29, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-------------+----------+--------------------+----------+\n|recid|      name|      segment|SCDcurrent|    SCDeffectiveDate|SCDendDate|\n+-----+----------+-------------+----------+--------------------+----------+\n|    1| FaetterBR|legetøjsbutik|      true|2022-01-17 17:12:...|      NULL|\n|    2|   ToysRUs|legetøjsbutik|      true|2022-01-17 17:12:...|      NULL|\n|    3|HammerFedt|     grovsmed|      true|2022-01-17 17:12:...|      NULL|\n+-----+----------+-------------+----------+--------------------+----------+"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamQuery.status"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 30,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:12:53.7851922Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:12:54.1586659Z",
              "execution_finish_time": "2022-01-17T17:12:54.5820984Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 30, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "{'message': 'Getting offsets from DeltaSource[abfss://cosmo@daxdatalakestorage.dfs.core.windows.net/synapse/workspaces/daxprojectcosmo/warehouse/sparkdb.db/testsource]',\n 'isDataAvailable': False,\n 'isTriggerActive': True}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change row already in sourcetable**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DeltaTable.forName(spark, 'sparkdb.testsource').update(\r\n",
        "  condition = col('name') == 'FaetterBR',\r\n",
        "  set = { 'segment': lit('våbenproducent') }\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 31,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:12:58.0854383Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:12:58.5046103Z",
              "execution_finish_time": "2022-01-17T17:13:09.7126992Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 31, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "spark.sql(\"SELECT * FROM `sparkdb`.`testsource`\").show(10)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 32,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:13:13.1679509Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:13:13.6563265Z",
              "execution_finish_time": "2022-01-17T17:13:16.5387015Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 32, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+--------------+\n|recid|      name|       segment|\n+-----+----------+--------------+\n|    1| FaetterBR|våbenproducent|\n|    2|   ToysRUs| legetøjsbutik|\n|    3|HammerFedt|      grovsmed|\n+-----+----------+--------------+"
          ]
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check target-table to see updated row**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "spark.sql(\"SELECT * FROM `sparkdb`.`testtarget`\").show(10)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 33,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:13:18.2249288Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:13:18.6854197Z",
              "execution_finish_time": "2022-01-17T17:13:21.5281677Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 33, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-------------+----------+--------------------+----------+\n|recid|      name|      segment|SCDcurrent|    SCDeffectiveDate|SCDendDate|\n+-----+----------+-------------+----------+--------------------+----------+\n|    1| FaetterBR|legetøjsbutik|      true|2022-01-17 17:12:...|      NULL|\n|    2|   ToysRUs|legetøjsbutik|      true|2022-01-17 17:12:...|      NULL|\n|    3|HammerFedt|     grovsmed|      true|2022-01-17 17:12:...|      NULL|\n+-----+----------+-------------+----------+--------------------+----------+"
          ]
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamQuery.status"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DAXSparkPoolv3",
              "session_id": 115,
              "statement_id": 34,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-17T17:13:25.3922299Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-17T17:13:25.8205533Z",
              "execution_finish_time": "2022-01-17T17:13:26.890018Z"
            },
            "text/plain": "StatementMeta(DAXSparkPoolv3, 115, 34, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "{'message': \"Terminated with exception: Detected a data update (for example part-00000-859ad800-9c19-459b-bd76-ec6688000785-c000.snappy.parquet) in the source table at version 3. This is currently not supported. If you'd like to ignore updates, set the option 'ignoreChanges' to 'true'. If you would like the data update to be reflected, please restart this query with a fresh checkpoint directory.\",\n 'isDataAvailable': False,\n 'isTriggerActive': False}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": "Test-notebook for SCD script",
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}